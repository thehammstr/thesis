% !TEX root = ../Thesis.tex

\chapter{Data Correspondence and Alignment}
\label{ch.LoopClosure}

SLAM methods like the the one described in Chapter \ref{ch.ProblemStatement} gain information about their accumulated navigational drift by making repeated observations of the same features or areas of the environment. Implicit in this task is the necessity to identify measurements as having come from observations of the same feature or terrain. This is the problem of data correspondence. 

The methods for solving the correspondence problem, the ease with which it can be solved, and the way information from these repeated observations are incorporated into the mapping solution are highly dependent on the specific context of the application. They depend on the type of sensing the robot has available to it, the distinctiveness of the features in the environment, etc. A method may solve the correspondence a priori, or attempt to discover correspondences during the mapping procedure. Similarly, it may extract navigational offset information beforehand, or allow this information to be incorporated more implicitly during the optimization.

The method presented in this chapter is derived from a form of loop closure detection commonly used in underwater sonar range-based mapping. Because of the difficulty in extracting distinct, discrete features from the sonar data, the method instead aligns aggregated submaps of data. This method can be split into two steps. First, there is a ``correspondence" step that hypothesizes that two submaps should have some degree of overlap (without explicitly assigning correspondence between any discrete points in the map). Second, the maps are aligned by some method to produce a relative position between the two submaps that is used to correct for drift in the SLAM optimization. 

This chapter examines how the iceberg's motion complicates this method for detecting and encoding loop closures, and proposes two methods for solving it. The first method is a graphical interface that allows a human to direct the search for loop closure events. An automated algorithm then operates on a reduced search space to perform precise alignment, and the user decides whether the alignment is good enough to include in the mapping optimization. This prevents the inclusion of false correspondences that result from becoming trapped in local minima, a common failure mode for distance-based registration algorithms like ICP.

The second method comprises early work toward full automation of the loop closure detection process and also serves as an additional human aid for detecting loop closure events. It borrows heavily from computer vision and image processing literature, applying robust image feature extraction techniques to sonar range data in order to detect loop closure. In essence, this method seeks to identify and describe ``landmarks" in the data that can be used to detect when an area has been visited before. 

 While the feature extraction and matching technique presented here was used only as an aid for the initialization of the submap alignment process, it shows potential for use in more discrete feature-based mapping techniques. With additional research, it could overcome some of the challenges for submap alignment caused by iceberg motion. These extensions will be discussed further in Chapter \ref{ch.FutureWork}.

\begin{figure}[htb]
   \centering
   \includegraphics[scale=.6]{../graphics/IcebergSLAM/IcebergSLAMphotos/Slide2.png} % requires the graphicx package
   \caption{Data correspondence for loop closure detection. }
   \label{fig:icebergSLAMLC}
\end{figure}

\section{The challenge of loop closure detection}

Inertial navigation errors, whether introduced by moving terrain or poor sensing, complicate the task of loop closure detection in several ways. This section gives a brief review of the underwater mapping technique described in Chapter \ref{ch.RelatedWork} to emphasize the role of loop closure in navigation and mapping. It then describes the particular challenges that arise from these errors.

\subsection{Data correspondence for iceberg profiling}

\subsubsection{Iceberg-specific simplifications}

In some ways, the data correspondence problem is simplified when mapping icebergs. This is because the iceberg can be thought of as a cyclical environment: assuming the vehicle maintains a constant depth and distance from the iceberg (both of which can be done with onboard sensors), if the AUV travels for long enough, it is for all practical purposes guaranteed to revisit the same portion of the iceberg multiple times. The positional uncertainty is effectively reduced to a 1-dimensional periodic problem. This is not true in general for traditional bathymetric mapping tasks, where a vehicle with sufficiently large drift could completely miss all previously observed terrain. 

This fact simplifies the data correspondence problem significantly. Given enough data, the problem statement becomes ``which of these data correspond to each other," as opposed to the harder question of ``do any of these data correspond to each other." Additionally, after the first circumnavigation has been completed, side-to-side overlaps provide many additional loop closures that increase the eventual map's accuracy, and for online implementations, can help keep the current position estimate converged within the current best estimate of the map.

%However, while this geometric fact reduces the dimensionality of the data correspondence search, it also places a lower limit on how much time can pass before the completion of the first loop. The time required to circumnavigate an iceberg depends on its size. While normal mapping can include as many loop closures as necessary for map accuracy, for larger icebergs, a long time may pass between the start of a mapping run and the completion of the first loop, giving motion effects time to compound. Once the first loop closure is detected, more between-swath matches will occur, but the time to complete the first loop may make initial loop closure detection more challenging.

\subsubsection{Complications due to motion} 

While the cyclical nature of iceberg mapping simplifies the problem, the iceberg's motion makes it more complicated. The iceberg motion introduces larger apparent odometry errors, which complicates the loop closure detection process in two ways: first, a larger area must be searched in order to guarantee overlap, and second, the submaps themselves can become warped relative to the true terrain shape, making correlation techniques less accurate and reliable.

%All inertial navigation systems drift over time without bound. This is a fundamental limitation of obtaining a position estimate solely by integrating noisy velocity and acceleration measurements. A modern state-of-the art INS can provide drift rates as low as 0.01\% of the distance traveled, but even this low a drift rate will eventually grow large enough to introduce substantial map error.  

In order to detect overlap in the face of large motion-induced odometry errors, a greater area must be searched. To do so, the submaps must either be large enough to cover the entire dead reckoned location uncertainty bound, or many submaps must be compared to determine the correct correspondence. This is illustrated in Figure \ref{fig:BathyMapping3}. As the uncertainty in localization grows, the associated error ellipse, and the area over which the algorithm must search for correspondences, increases.

 \begin{figure}[htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/GraphSLAMcartoons/deadReckoning.png} % requires the graphicx package
   \caption{The black points are the estimated/planned trajectory. The red points are the actual trajectory. Blurred ellipses show the positional uncertainty due to dead reckoning. The greater the inertial navigation error, the larger the search ellipse for loop closure detection.  }
   \label{fig:BathyMapping3}
\end{figure}

The second complication arises from the ICP alignment algorithm's implicit assumption of submap rigidity. The submap creation assumes that the inertial guidance of the vehicle is accurate over the short time it takes to build a submap, as described in Chapter \ref{ch.ProblemStatement}. Any navigation errors during that time will introduce warping to the submap, which can cause the registration method to fail or worse: create a positive match on different terrain. This warping effect makes the comparison of ever-larger submaps problematic, as the alignment accuracy will degrade as the submap shape diverges from its true geometry, as shown in Figure \ref{fig:motionErrorWarping}.
 
 \begin{figure}[htb]
   \centering
   \includegraphics[width=.9\textwidth]{../graphics/WarpEffect.png} % requires the graphicx package
   \caption{The black curve is the true surface. The red points are the surface as reconstructed by a vehicle whose heading rate estimate is drifting.  }
   \label{fig:WarpingEffects}
\end{figure}

For reference, on a typical iceberg mapping mission, the warping effect would become noticeable after about 100m. At 40m standoff distance from the wall, assuming ranging error of 1\% of distance traveled, a submap's shape would be accurate to roughly $\pm$ 40cm. This serves as a benchmark for quantifying the warping due to odometry errors caused by iceberg motion. To consider the worst-case scenario, assume a relatively fast-rotating iceberg motion of 20 deg/hr. This motion, if not accounted for will manifest as a heading gyro bias. The vehicle travels at 1.5 m/s. If the vehicle is actually moving in a straight line, the 20 deg/hr bias will cause the odometry estimate to move along 15 km radius circular arc. After 100 m of travel, the difference between the true path and the estimated path will be comparable to the 40 cm sonar range error. If the submap remains shorter than this, any motion-induced warping will remain below the noise. Above it, and warping becomes a noticeable effect. This is illustrated in Figure \ref{fig:WarpingEffects}.

In light of this warping related to submap size, there is an incentive to search for correspondences between numerous smaller submaps. This mitigates the alignment errors associated with the warping, but requires that the algorithm perform explicit data correspondence, as described in Section \ref{sec:explicitDataCorr}.

 \begin{figure}[htb]
   \centering
   \includegraphics[width=.9\textwidth]{../graphics/warpedWall3View.png} % requires the graphicx package
   \caption{The effect of heading drift rate error on map warping. In red is a high elevation view of 11 minutes of data from a vertical section of Soquel Canyon. It is projected with no heading rate error. The green and blue clouds are the same data, but have heading rate errors of $\pm0.001$ rad/s. Note how the edges of the warped map curl away from truth.}
   \label{fig:motionErrorWarping}
\end{figure}

%One possible solution to achieve large coverage area with minimal map warping might be to search for the best registration over multiple smaller submaps, and devise a metric to select the best submap alignment pair. However, as odometry error increases, the search space can become large. Point cloud registrations are relatively expensive, and verifying their alignment can be difficult. 

These concerns provide the motivation for the methods developed in the rest of this chapter. The first one, a graphical user interface, leverages humans' pattern recognition ability to provide high-level guidance and error checking for the alignment algorithm. It provides a streamlined method for encoding loop closure information, and guards against local minima and false matches. 

The second method works toward removing the need for human intervention entirely. Borrowing from well-developed concepts in the computer vision and image processing communities, and more recent work in point cloud feature extraction, it seeks to find local, stable, identifiable features in the terrain that can be recognized upon a second observation. These distinctive ``landmarks" can be used to initialize more accurate point cloud registration methods, avoiding convergence into local minima. 


\section{Loop closure GUI}
\label{sec:GUI}

\subsection{GUI Operation}

This section describes the graphical user interface that was designed as a tool to allow a user to identify and encode loop closures quickly and easily. As a general rule, the more loop closures that are incorporated into the optimization, the more accurately the iceberg motion can be accounted for, yielding a more accurate and self-consistent map. The GUI allows dozens of matches to be detected and encoded in a matter of minutes. Figure \ref{fig:GUI1} shows the general interface, and detailed instructions on use can be found in Appendix \ref{ap.GUI}.

 \begin{figure}[ht]
   \centering
   \includegraphics[width=.9\textwidth]{../graphics/guiscreenshots/GUIsim.png} % requires the graphicx package
   \caption{Loop closure GUI being used to encode loop closures on Soquel Canyon data set }
   \label{fig:GUI1}
\end{figure}

The user loads a file consisting of raw navigation data and sonar range returns into the program, and the data is used to produce a trajectory estimate and point cloud of the ensonified terrain. Any odometry errors or unmodeled iceberg motion will introduce inconsistency into the point cloud. 

Using a slider bar, the user can estimate a constant rotational bias in the navigation solution. This bias is immediately incorporated into the visualization, aiding in the process of identifying regions of overlap by eye. 

Once the user determines that two areas correspond with high likelihood, he or she can highlight the regions and launch ICP to find the offset between these submaps. Upon convergence of the ICP algorithm, the user is then given the opportunity to accept or reject the alignment, before incorporating it into the GraphSLAM optimization. 

At this point the user can launch GraphSLAM or continue to encode more loop closures, and proceed iteratively until convergence.


\section{Toward loop closure automation}

%The amount and type of information that can be extracted from terrain varies widely by the sensing modality. For multibeam sonar, only range and intensity (effectively reflectivity) are returned by the sensor. This dissertation only considers information that can be obtained from the range information, though future work may investigate the value of intensity for loop closure detection purposes.

\subsection{Applying 2D image features to 3D terrain}

%A wealth of research has been conducted in extracting robust, identifiable features from 2D imagery. The following section details work that leverages this well-established technology for the problem of recognizing 3D terrain. It was hypothesized that since many image processing techniques convert images to a format identical to DEMs, the techniques developed for imagery may be useful when dealing with actual maps of terrain.   Although this work is still in its early stages, the hypothesis appears to be supported by data from an underwater canyon mapping mission.

%\subsubsection{Creating images from terrain}

Feature extraction techniques initially developed for image analysis can provide a means to automate the detection of loop closure events in sonar data. The genesis of this idea came from the observation that it was difficult to identify patterns by eye from raw sonar point cloud data, but that it became easier to recognize patterns when the data was projected onto a plane and false-colored by height above the plane. Essentially, converting raw submap point clouds to a format similar to topographic charts facilitated pattern recognition for human users.

Many standard algorithms (e.g. SIFT and SURF) for extracting robust image feature descriptors only consider image intensity, discarding any color information. The resulting grayscale images are identical in form to digital elevation maps (DEMs), with pixel intensity being the ``height" of the map above that location in the image. This representation is shown in Figure \ref{fig:imAsSurf}. 

\begin{figure}[htb]
   \centering
   \includegraphics[width=\textwidth]{../graphics/imageAsSurf.png} % requires the graphicx package
   \caption{Algorithms like SIFT and SURF treat images as digital elevation maps, with intensity plotted as height. Note how brighter areas in the photo correspond to higher peaks. The algorithms use gradient information to detect and describe local stable features.}
   \label{fig:imAsSurf}
\end{figure}

In order to produce an image from range data, a few steps must be taken. First, a reference plane and corresponding projection direction must be chosen. A grid is constructed on the reference plane, and the distance between a sounding and its projection onto that plane is encoded as the ``intensity" of the resulting image. For instance, when creating a normal DEM map of the seafloor, the reference plane is horizontal $(x,y)$, and the projection direction is vertical $(z)$ (for instance, the NED coordinates used in the UTM system). However, operating around an iceberg, with vertical or even undercut sides, creates an ambiguity as to which direction the projection should occur. 

The method presented here calculates the average normal for the entire submap and uses that as the projection direction. The reference plane is set perpendicular to this, such that all soundings lie on the positive-$z$ side of the plane.

When applied to the sonar submap shown in Figure \ref{fig:submap_rangeImage}, this yields the image shown in Figure \ref{fig:holyImage}. Sonar occlusions result in a number of holes or gaps in the data. This does not occur in camera imagery, as the data is collected  all at once, and projected directly onto the camera's imaging sensor. Additionally, sometimes a number of soundings project to the same pixel. To handle the latter case, the average pixel height is used in the final image. 

The gaps in the data are filled by a process equivalent to bilinear interpolation in order to prevent the feature extraction algorithm from interpreting them as valid information. A mask is used to prevent features from being detected within the unobserved regions. However, since the algorithm uses pixel neighborhoods to detect and describe features, the gaps must be smoothed in. The fundamental assumption here is that the sonar returns are the result of reflecting sound energy off of an underlying physical \emph{surface}, implying that nearby measurements will be correlated.  To reflect this, the algorithm smooths the transition to the unobserved regions using an iterative procedure of eroding the full image and then restoring the known pixels to their original values.

The pixels lacking data are initialized with a value of $0$. The image is then convolved with a Gaussian kernel, which acts as a low-pass filter, effectively smearing the image, filling in some of the gaps. 

\begin{figure}[htb]
   \centering
   \includegraphics[width=.9\textwidth]{../graphics/submap_rangeImage.png} % requires the graphicx package
   \caption{A submap of sonar measurements collected in Soquel Canyon.}
   \label{fig:submap_rangeImage}
\end{figure}

\begin{figure}[htb]
   \centering
   \includegraphics[width=.8\textwidth]{../graphics/holyImage} % requires the graphicx package
   \caption{A DEM created from the data shown in Figure \ref{fig:submap_rangeImage}. Notice that since the data was recorded from multiple viewpoints and the projection is not aligned with a single camera boresight, the resulting images has a number of holes.}
   \label{fig:holyImage}
\end{figure}

The second step restores the pixels that began with valid data to their original values. This process of smoothing and replenishing known data to their original values is repeated until the image converges, and more iterations do not change the values of the pixels. The result is equivalent to bilinear interpolation in the unpopulated areas, and preserves the values of the valid data. The result of this process can be seen in Figure \ref{fig:rangeImage}

\begin{figure}[htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/lowcontrast2.png} % requires the graphicx package
   \caption{After the erode-restore process, the gaps in the image are smoothed out, but the original structure remains.}
   \label{fig:rangeImage}
\end{figure}

The last step in creating a high-contrast image for feature detection is to apply Contrast-Limited Adaptive Histogram Equalization (CLAHE). Algorithms like SIFT and SURF use gradient information in images to extract the features. The CLAHE process attempts to enhance details without skewing the overall contrast level of the image \cite{Reza2004}. Figure \ref{fig:rangeImageHC} shows the result of this step.

\begin{figure}[htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/rangeImage.png} % requires the graphicx package
   \caption{Adaptive Histogram Equalization boosts the detail of the image, making it easier for algorithms like SIFT to find features.}
   \label{fig:rangeImageHC}
\end{figure}

Robust image features can be extracted from the resulting image and used to look for loop closure events. The work presented here uses SIFT features, though other feature classes could be used. Figure \ref{fig:SIFTrangeImage} shows some features extracted from such an image, and Figure \ref{fig:matches} shows how these features can be matched. Upon reimaging a portion of terrain and extracting a second set of features, matching is performed. Random Sample Consensus (RANSAC) \cite{Fischler1981} is used to screen for false matches by enforcing geometric consistency between the matches. If a consistent model can be found using a sufficient number of matches, there is a high likelihood that the two submaps correspond to the same terrain, and precision alignment can be performed using ICP with reduced risk of false alignment. 

\begin{figure}[htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/SIFTrangeImage.png} % requires the graphicx package
   \caption{A random sampling of SIFT features extracted from the range image.}
   \label{fig:SIFTrangeImage}
\end{figure}

\begin{figure}[htb]
   \centering
   \includegraphics[width=.9\textwidth]{../graphics/siftMatches.png} % requires the graphicx package
   \caption{SIFT feature matches between two successive passes by the Soquel Canyon wall. }
   \label{fig:matches}
\end{figure}

\subsubsection{A note on robustness}

2D image feature techniques are powerful, but they cannot create information where there is none. If the terrain is perfectly flat and featureless, they will not produce meaningful results. 

The matching techniques described above treat the features as if they lie in a plane, which is not necessarily a valid assumption. The same terrain, when projected in different directions can change appearance drastically. Using the average normal of the point cloud data as the projection direction for the range image, as described above, is a simple heuristic. While this method has produced good results in the datasets used in this research, some geometries could prove challenging. For instance, terrain with highly nonplanar geometry or multiple major planar regions could make choosing a single direction in which to project the data difficult.  

Figure \ref{fig:lighting} shows the images resulting from projecting the same range data in a number of directions. The central image uses the average normal plane. Above and below it represent $\pm 15$deg of elevation and left and right $\pm 15$ deg of azimuth, relative to neutral. While the images remain qualitatively similar, the ability to detect the same SIFT keypoints reliably falls off between 5 and 10 degrees off-nominal.

\begin{figure}[htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/rangeImageLighting.png} % requires the graphicx package
   \caption{The range image remains relatively consistent over $\pm 15$deg of azimuth and elevation change in projection direction. Qualitatively, it looks like changes in lighting over the terrain, for which image features like SIFT and SURF claim some robustness \cite{Lowe2004} }
   \label{fig:lighting}
\end{figure}

\subsection{Automated correspondence detection usage}

The feature-based automated loop closure detection method described above is currently used to initialize the ICP alignment method that drives the optimization process. Since introducing false correspondence information to the mapping process can introduce large errors or cause it to fail to converge, conservative thresholds are used to ensure extremely high confidence in the detected matches. For example, the results presented in Chapter \ref{ch.Results} require six additional inliers after performing RANSAC during matching, totaling ten geometrically consistent matches between images. While this makes the chances of detecting a false positive match very low, it also rejects a number of valid matches. However, even with only one or two matches, the optimizer can get close enough to the true solution that detecting more correspondences, either by hand or using distance-based metrics, becomes trivial.

The automated method also holds potential to enable full online automation of the map creation process, but will require further effort to improve robustness to the point where it can be used by vehicles in the field. The methods put forth in this Chapter are meant to serve as a proof of concept, demonstrating that information within the natural texture of an iceberg or canyon can be used to detect loop closure events in the presence of large navigational uncertainty. Further work to detect and provide robustness to degenerate cases would be invaluable for a rugged, deployable solution, but the method presented here lays the groundwork for such a solution. Some possible approaches that would augment  the capabilities presented here are discussed in Chapter~\ref{ch.FutureWork}.


%\section{3D Point Cloud Features}
% 
% \subsection{Using Invariant Information to Improve Feature Discriminative Power} 
%
%
% 
%Recent advances in the affordability and capability of ranging sensors has spurred research in the development of robust point cloud features akin to those used in 2D image processing. They seek to encode local information contained in the point cloud in order to classify interest points or compare with databases of known shapes. 
% 
% \subsection{Curvature and Normal Vector Estimation}
%
%Surface curvature and normal vector direction are two parameters that are often estimated from local patches of point cloud data, and can provide useful information. 
%
%A number of methods exist, but the most efficient method uses principal component analysis to fit a plane to a small neighborhood of points. 
%
%\begin{align} % requires amsmath; align* for no eq. number
%   C = ~&\frac{1}{K} \sum\limits_{k=0}^{K} (\mathbf{p}_k - \mathbf{\bar{p}})  (\mathbf{p}_k - \mathbf{\bar{p}})^\intercal \\
%   \sigma_i\mathbf{\lambda}_i = &~ C\mathbf{\lambda}_i
%\end{align}
%
%Here $\mathbf{p}_k$ are the $K$ nearest neighbors to the point of interest. $\mathbf{\bar{p}}$ can either be the mean of the patch or the interest point itself. These will be very similar except on the boundaries of a point cloud.
%
%The normal to this plane is the eigenvector corresponding to the minimum eigenvalue \cite{?}. The curvature can be estimated as the ratio of eigenvectors
%
%\begin{align} % requires amsmath; align* for no eq. number
%   \kappa = ~&\frac{\sigma_{1}}{\sigma_{1}+\sigma_{2}+\sigma_{3}} 
%\end{align}
%
%or a more complex model, such as a quadratic paraboloid can be used. The former method is simpler, but can fail in noisy point clouds where there is not a single clearly-defined surface. The latter method is used in the 3D extension of Harris Corners \cite{Harris3D}.
%
%Curvature can be used to extract features in the terrain, for later use in comparison. This solves the first problem for extracting landmarks from the terrain: ensuring that these points of interest are well-localized, as discussed in section \ref{sec.2Dfeatures}.  A simple feature descriptor can be constructed based off the curvature and normal vector to aid in the comarison. 
% 
% !TEX root = ../Thesis.tex

\chapter{Related Work}
\label{ch.RelatedWork}

This chapter organizes related work in two main categories: application and methods. The former section looks at previous efforts to create 3D reconstructions of icebergs by a number of methods. The latter section focuses on prior work in robotic mapping of static terrain, with an emphasis on underwater mapping and simultaneous localization and mapping (SLAM) tasks. Spanning these two areas is work by Kimball and Rock \cite{Kimball2011}, which used SLAM techniques to perform iceberg profiling.

Additionally, a section is dedicated to methods previously used for solving the data correspondence problem within SLAM, including computer vision techniques, and other methods from the robotics literature.

\section{Iceberg Profiling}

A number of methods exist for generating shape estimates of free-drifting icebergs. They can be broken down roughly by the type of data used to produce the method: aerial measurements, ship-based measurements including tethered vehicles, and untethered underwater vehicle (UUV) based measurements.

\subsubsection{Aerial Iceberg Profiling}

Aircraft are used extensively in tracking and managing icebergs. Coast Guards and Navies of several nations regularly patrol Arctic and Antarctic waters to detect and track icebergs that might pose a threat to infrastructure or shipping. While this provides an effective means of tracking icebergs' positions over time, it says relatively little about the iceberg's structure. The aircraft are sometimes equipped with LIDAR range scanners [\cite{?}], but most often the only measurements available are photographs. From this, rough classification of iceberg type based on sail shape (such as ``drydock," ``pinnacle," or ``blocky" ) is possible. Additionally, keel depth can be estimated heuristically based on maximum waterline length, and decay rate can be inferred from repeated sightings, as shown in \cite{Barker2004}. However, all of these are only first-order approximations of shape; aerial imagery cannot provide detailed iceberg shape profiles. 

\subsubsection{Ship-based Iceberg Profiling}

A number of companies use ship-based measurement to profile icebergs. These methods comprise both above-water and below-water observations, yielding a full shape reconstruction of both the sail and keel of the iceberg. 

Above-water measurements include radar, lidar, and image-based photogrammetry techniques. Lidar-based approaches can provide dense point cloud measurements of the iceberg's sail, yielding a very high resolution reconstruction. An added benefit of this sensing method is that the lidar point clouds have sufficient overlap in the ship's direction of travel to directly measure the iceberg's motion, as shown in \ref{fig:LidarOdometry}. This method is also used in ship-hull inspection, as in \cite{Papadopoulos2014} where the scan matching provided such accurate hull-relative odometry that the inertial measurements were essentially ignored, and the position estimate from the lidar was used to project sonar measurements to create the keel portion of the map.

To map the keel, multibeam or sidescan sonar is typically used. For very large icebergs, surface-based observation can be insufficient to measure deeper portions of the keel. Tethered ROVs or tow bodies outfitted with sonar can be used to access the lower parts, and even the bottom of the keel, but drive up the cost and complexity of the operation, and can put expensive assets at risk. 

The ability to make simultaneous observations of the iceberg both above and below the surface, combined with the differences in available sensing between these two media, allows the iceberg motion to be measured directly, simplifying the task of resolving the data into the moving reference frame. This is the chief advantage of surface-based measurement techniques. Disadvantages include high cost, risks involved in operating close to icebergs, and the inability to profile deep portions of the iceberg. Using a sonar-equipped tow body or ROV can allow access to deep portions of the keel, but can drive up cost and complexity of the operation. 


\subsubsection{AUV-based Iceberg Profiling}

Several efforts have investigated the use of AUVs for iceberg profiling. These have been motivated in large part by AUVs' low operational cost relative to ROVs and ship-based methods. Additionally, AUVs could enable some missions that would simply be infeasible for ROVs, such as mapping very large icebergs, or ice islands. 

Zhou et. al. have investigated using Slocum Glider vehicles to profile icebergs between Greenland and Newfoundland and Labrador. \cite{Zhou2014}. Icebergs are prevalent there, and pose risk to offshore oil installations and shipping. Gliders show promise as a low-cost data collection platform to aid in iceberg management, but their low power and control authority constraints limit their achievable resolution. However, cooperative efforts with autonomous surface vehicles show great potential for improving this \cite{Smith2014}. The focus of this work has been developing a control strategy for the glider, given its motion constraints, that allows application to iceberg profiling. It assumes that the iceberg's motion can be adequately described purely with translation. This assumption is likely valid for small icebergs, which do not take long to profile, but breaks down for much larger icebergs, where drift has longer to accumulate. Additionally, the vehicle dynamic, sensing, and power constraints make a difficult to perform a direct comparison between their methods and the one presented in this dissertation. 



%\begin{figure}[!htb]
%   \centering
%   \includegraphics[scale=.4]{../graphics/KimballIterativeOpt.png} % requires the graphicx package
%   \caption{Iterative optimization structure employed by Kimball. The nonlinear heading parameters $\psi$ are chosen in the outer loop and fed to the inner loop as constants. $\hat{\bar{x}}_{ls}$ is a vector of O(10) motion parameters and O(1000) iceberg-fixed points to be estimated at each optimization step  \emph{Graphic courtesy of Peter Kimball}}
%   \label{fig:NestedLoopRelatedWork}
%\end{figure}

\section{Simultaneous Localization and Mapping}

The method for iceberg profiling employed in this thesis extends traditional infrastructure-free, AUV-based bathymetry mapping techniques to the moving iceberg reference frame. This method seeks to generate an accurate trajectory estimate and reproject the measurements to create a self-consistent point cloud.To account for the potentialy large errors introduced by the iceberg's motion, it correlates measurements taken of the same area of the iceberg at different times, to estimate the accumulated drift. Since this method uses terrain information to generate an accurate trajectory estimate, while at the same time using its trajectory estimate to build a map of the terrain, it falls within a class of algorithms known as Simultaneous Localization and Mapping, or SLAM.

SLAM allows a robot to reconstruct an unknown environment and localize itself within that environment simultaneously.  The common thread between all these algorithms is that they attempt to maximize measurement consistency, balancing errors in motion measurements (odometry) with map geometry errors based on repeated observations of features within the environment (measurements).

\subsection{SLAM Overview}

Most SLAM methods begin with a similar high-level problem formulation, then differ in solution technique depending on sensing, required map accuracy, computation limitations, etc. This section will present a high-level example of a simple, generic SLAM problem formulation, then discuss some of the different variants, applications, and challenges in performing SLAM. 

\subsubsection{SLAM example problem}
\label{sec:genericSLAM}
A classic SLAM problem involves a wheeled vehicle creating a map of an unknown environment as it navigates through it, as shown in Figure \ref{fig:GenericSLAM} The vehicle is outfitted with sensors that provide information about both its own motion through the environment, as well as the structure of the environment itself. For this simple example, the vehicle is assumed to have wheel encoders, a compass, and a laser range scanner to observe distance to its surroundings in all directions.

 \begin{figure}[!htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/genericSLAM.png} % requires the graphicx package
   \caption{ Generic SLAM example}
   \label{fig:GenericSLAM}
\end{figure}


In this simple example, the vehicle has knowledge of its ego-motion via onboard odometry sensors: wheel encoders tell how far the robot has rolled over a given time, and a compass gives the vehicle's heading. The vehicle can combine this information to estimate its path through the environment via dead-reckoning, but over time, these integrated measurements will drift away from the true position, which will also cause the .

If left unaddressed, the odometry drift would cause the projected range measurements of the environment to become inconsistent: multiple observations of the same feature or area would appear in different locations. To combat this, repeated observations of the same area are used to estimate and correct the accumulated drift, a process known as loop closure. In the example case, laser scans are aligned to produce an estimate of the translational and rotational drift that has accumulated between observations. 


\subsubsection{SLAM variants}

A wide variety of SLAM techniques have been developed and applied to mapping tasks in countless environments with all types of vehicles. A detailed enumeration of these methods would fill many volumes, and is well beyond the scope of this document, but for a good summary, the reader is encouraged to refer to \cite{SLAMoverview}. While each method has its own nuances, these methods can broadly be categorized along a few axes, based on data representation and solution methods. 

One distinguishing feature of a method is whether it runs online or offline. EKF SLAM uses a Gaussian representation to run online, while GraphSLAM is applied after all data has been collected to solve for trajectory and map in one large batch process \cite{} \cite{}. Some methods, such as FastSLAM, can be applied both online and offline \cite{FastSLAM}.

A second difference between SLAM methods involves how the method represents the map. Some methods use a ``feature based" approach, where the map is composed of discrete, identifiable units whose positions are estimated. \cite{?}. Other methods are non-feature based, using other means to represent the map. An example of this is occupancy grid mapping, where the environment is discretized, and each discrete region is assigned a ``probability of occupancy." In other words, how likely it is that a position contains something solid, based on observations over time.  A third type of SLAM does not explicitly represent the map at all, but uses information in the environment to impose relative pose constraints between parts of the robot's trajectory. These methods are often not classified as SLAM, since the map itself is not one of the optimization variables. However, since terrain observations are used to generate localization estimate,  the localization portion and mapping portion cannot be decoupled, and these methods can indeed be thought of as SLAM. 

This dissertation uses the GraphSLAM algorithm \cite{Thrun2006} to provide an offline estimate of iceberg shape. This will be developed fully in Chapter \ref{ch.GraphSLAM}. 

\subsection{SLAM in Underwater Environments}

SLAM has been used in a number of underwater applications, using many different sensing modalities. Fairfield et. al. mapped naturally-occuring cenotes in Mexico using an efficient occupancy-based SLAM technique \cite{Fairfield2007}. A number of research efforts have performed SLAM in structured or manmade underwater environments like dams and marinas \cite{Ribas2008}. In shallow, highly textured environments like coral reefs, a number of image-based SLAM implementations have been successful \cite{Eustice2005}.

The ``standard" method for bathymetry mapping uses submap correlation to estimate drift, and then distributes the accumulated errors evenly over the trajectory history. An example of this is shown in Figure \ref{fig:BathyMapping}. The black lines show the vehicle's online estimate of its path as it collected data. The red lines show the best estimate after correlating measurements during loop closure events, when the vehicle revisits previously-observed terrain. These two are nearly identical in the right side of the map, where there are no self-intersections, while they differ more on the left, where the vehicle trajectory self-intersects a number of times. Without these loop closure events, there is no additional information with which to correct any accumulated drift. While not typically referred to as SLAM, the use of terrain correspondence to estimate and correct navigation errors represents essentially the same high level approach \cite{Henthorn2006}.  Roman and Singh used a delayed-state Extended Kalman Filter SLAM approach to improve map resolution over the traditional uniform smoothing approach by making explicit the position estimate uncertainty\cite{Roman2005}. This differs from the previous approach in that it does not make the assumption that the error is evenly distributed. While the delayed-state EKF implementation can be run online, the need to append states to the estimate as the mission progresses limits the maximum survey size.

 \begin{figure}[!htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/NavPerformance.jpg} % requires the graphicx package
   \caption{Illustration of normal bathymetric mapping procedure (lawnmower pattern). The trajectory self-intersects a number of times. These crossings, or loop closure events, can be used to estimate navigational errors. The red path is the real-time inertial estimate and the black path is the corrected trajectory. Up to 30 meters of correction was necessary. \emph{www.mbari.org} }
   \label{fig:BathyMapping}
\end{figure}


\subsection{Data Correspondence and Alignment}

SLAM methods generally rely on identifying loop closure events, where an area is revisited after a long interlude. Multiple observations of recognizable features are then compared, and any discrepancy in their estimated location can be used to correct navigational error in the robot's trajectory. The first part of this process, often referred to as the \emph{correspondence} problem, involves determining that two or more measurements correspond to observations of the same feature or area in the environment. Data \emph{alignment} then aims to resolve any discrepancies between the multiple observations by modifying the trajectory estimate. Determining relative weights between odometry errors incurred by these modifications and observation discrepancies is highly application-specific, as are the methods used to solve the correspondence and alignment problems. These are separate but coupled tasks: if the method used for alignment is very robust to outliers, the correspondence problem need not be overly discriminative. However, if the alignment method is sensitive to initial conditions or false correspondences, the correspondence must do a better job of rejecting bad matches. 


\subsubsection{Scan matching}

Scan matching techniques are very commonly used when a relatively good initial estimate of location is available, and onboard sensors produce dense 3-D range measurements. Rigid point clouds, or ``submaps" are created from one or more scans, and these scans are correlated to estimate rotation and translation offset. This process is illustrated in Figures \ref{fig:ScanMatch1} and \ref{fig:ScanMatch2}. These methods can be distinguished from later feature-based methods in that they do not build an abstract descriptor of an area, instead matching submaps in metric space based on the scene geometry. In the most simple implementations, the scene is assumed to be rigid, and a rigid transformation (rotation and translation) is estimated to account for misalignment between the clouds, though more advanced variants designed to deal with nonrigid bodies have also been described in the literature \cite{nonrigidICP} The correlation method most commonly uses some variant of the Iterative Closest Point algorithm (ICP) \cite(Besl1992) or grid search \cite{GridSearch}. The former method is faster than the latter, but more prone to local minima. Both methods can fail when the initialization is too far from the true offset. 

These techniques have been employed successfully in the field, including underground mine mapping \cite{ATLAS}, autonomous mapping of urban environments \cite{ref:Montemerlo}, and many underwater bathymetric mapping tasks \cite{}.

%If the AUV were operating above water, powerful 3D laser scanners would allow a direct measurement of rotation and translation between measurements reducing or eliminating the errors associated to iceberg motion. This is shown in figure \ref{fig:ScanMatch}. These types of scanners can map and perform odometry simultaneously, and are often used on terrestrial robots and Unmanned Surface Vehicles, but do not work underwater \cite{Papadopoulos2014}. The multibeam sonars available to an AUV only scan in two dimensions. For mapping the iceberg, the sonar is oriented with the beam oriented perpindicular to the direction of travel in order to sweep out the widest area, as shown in Figure \ref{fig:beamOrientation}.  In order to perform scan matching for odometry, the sonar would need to be oriented in the horizontal plane, as in Figure \ref{fig:ScanMatchMultibeam}. This drives a need for environment-aided localization techniques, as described above. 
%
%\begin{figure}[!htb]
%   \centering
%   \includegraphics[width=.8\textwidth]{../graphics/ScanMatch4a.png} % requires the graphicx package
%   \caption{Top view of the iceberg mapping problem. If the sensor field of view has significant extent in the direction of travel, scan matching can provide odometry}
%   \label{fig:ScanMatch1}
%   \end{figure}
%    \begin{figure}[h]
%   \centering
%   \includegraphics[width=.8\textwidth]{../graphics/ScanMatch4b.png} % requires the graphicx package
%   \caption{Odometry corrected by scan matching. This readily extends to the full 3d case using techniques like Iterative Closest Point.}
%   \label{fig:ScanMatch2}
%\end{figure}
%
%\begin{figure}[h]
%   \centering
%   \includegraphics[width=.8\textwidth]{../graphics/ScanMatch3.png} % requires the graphicx package
%   \caption{Simulated AUV scans taken at two times, roughly 20 meters apart. The multibeam mapping sonar sweeps out a wide area when oriented perpendicular to the direction of travel. This orientation does not allow scan matching for odometry, since the beam pattern does not overlap from scan to scan, as shown in Figure \ref{fig:NoMatch}}
%   \label{fig:beamOrientation}
%\end{figure}
%
%\begin{figure}[h]
%   \centering
%   \includegraphics[width=.8\textwidth]{../graphics/ScanMatch3a.png} % requires the graphicx package
%   \caption{This shows the same plot as Figure \ref{fig:ScanMatch1}, but with a vertically-oriented multibeam sonar, as used in mapping, as opposed to a horizontally-mounted multibeam or 3D range scanner. This orientation does not allow scan matching for odometry, since the beam pattern does not overlap from scan to scan.}
%   \label{fig:NoMatch}
%\end{figure}
%
%\begin{figure}[h]
%   \centering
%   \includegraphics[width=.8\textwidth]{../graphics/ScanMatch1.png} % requires the graphicx package
%   \caption{A multibeam sonar could be used for odometry as in Figure \ref{fig:ScanMatch2} if mounted in the horizontal plane as shown, but only for trajectories at constant depth, as the field of view would be very narrow in the vertical direction. However, this configuration could only map a thin layer of the iceberg at a time, so it is unsuitable for the mapping mission.}
%   \label{fig:ScanMatchMultibeam}
%\end{figure}
%


\subsubsection{Robust 2D image Features}
\label{sec.2Dfeatures}
A wealth of literature exists on the detection and description of robust features from 2-D images. These include Harris Corners \cite{Harris}, SIFT and SURF features \cite{Lowe} \cite{SURF}, ORB features \cite{ORB} Histogram of Gradients (HoG) \cite{HoG}, to name only a few. The different types of features generally employ a number of useful heuristics to detect well-localized keypoints in an image and build a descriptor based on the information contained near that keypoint that can be used to compare it with keypoints extracted from other images. 

The performance under various metrics depends on the specific task for which the feature was developed, e.g. human detection \cite{ }, rigid object detection/classification \cite{?}. An additional differentiator between methods is the amount and type of invariances a descriptor has, such as lighting, translation, scale, and rotation. For instance, a rotation-invariant feature produces the same descriptor for a keypoint regardless of the rotation angle of the original image. These invariances are useful at identifying features when the viewpoint differs greatly, but can obscure information when parts of the viewpoint are known, and often carry computational burden. 

Although the specific implementation details of each feature type differ, they all share some general characteristics:

First, they extract \emph{keypoints} from an image. The keypoints should be well-localized within the image. For instance, a sharp corner or discrete spot is well-localized in two dimensions, while edges and patches of uniform color or intensity are not. To determine these keypoints, gradient information is extracted from the image, and points having high gradients in multiple directions are considered stable enough to be used as a keypoint. 

Second, information in the local neighborhood of the extracted keypoint is used to create a descriptor for later comparison. Again, the details of these descriptor methods vary, but they often include histogrammed gradient information in many directions for robustness. 

There are several advantages to the use of these abstract descriptors. First, they can allow more robust and efficient comparison of keypoints from images than possible by using the raw data. Second, they can allow for data compression, whereby the important information about a keypoint can be retained while the rest of the image need not be stored. This could be of use on memory-constrained vehicles where recognition of loop closure events is important, but image data is not required for the mission. Third, because the descriptors reside in abstract high-dimensional descriptor space, their comparison does not require any position information. This circumvents the accurate initialization constraint of scan matching, and as such is of particular interest in the iceberg mapping problem.

At the time of writing, the Scale-Invariant Feature Transform (SIFT) developed by Lowe \cite{Lowe} remains the ``gold standard" in terms of stability, invariance, and descriptive power, but its computational complexity and the fact that it is patented continues to spur competing technologies. \cite{challengers}

\subsubsection{3D Point Cloud Features}

Recent advances in 3D range sensor technology have driven down the cost of these sensors and made them much more prevalent. As a result, researchers have begun to adapt many of the concepts employed in 2D image feature descriptors to 3D data. Rather than aligning entire point clouds as in scan matching, local geometry is used to describe stable keypoints within 3D data, for use in object classification and matching. 

These techniques range in their computational complexity and descriptive power, from simply estimating normal vector direction and curvature at keypoints (e.g. 3D Harris Corners) to the Fast Point Feature Histogram (FPFH) descriptors developed by Rusu et. al. \cite{}, and even a 3-D variant of the SIFT feature extractor \cite{}. These descriptors share many design principles with image features, such as histogramming gradient and direction information, and have been implemented in object recognition tasks with some success \cite{FPFH}. Of particular interest is work using FPFH features to supply an initial alignment estimate via RANSAC for more accurate ICP solutions. These techniques will be discussed further in Chapter \ref{ch.LoopClosure}

However, these techniques are less mature than their 2D image feature counterparts. Part of this stems from the fact that they represent a newer area of study, but another part is due to the sensing modality itself. A 3D range measurement  can provide depth information that a single camera does not, but cannot necessarily observe the color changes or small textural details that 2D features cue on. Additionally, 3-Dimensional objects do not have a single well-defined normal direction upon which to reference extracted features, which can add ambiguity to the feature extraction and comparison processes. 

Most of the work done with this class of 3D feature has been in manmade environments or with manmade object detection \cite{??} CITATIONS! . LOOK FOR WORK IN NATURAL TERRAIN!


%The methods vary in the amount of human involvement required, the quality of sensing ava as well as how coupled the loop closure detection is from the solution method. At one extreme is SLAM with known correspondence, either from hand-labeled data or by having a ``map" comprising highly distinguishable features, such a the coded transponder beacons used int \cite{xponderslam?}. At the other end of the spectrum is fully unsupervised SLAM, where raw data is fed to the algorithm, and loop closure is detected automatically. This class of solution is desirable from an automation standpoint, as hand-labeling data or verifying corresondences can be a tedious and cumbersome task. However, without supervision, more sophisticated error checking and outlier rejection is required during optimization, which can increase computational complexity greatly. The ability to perform automatic loop closure detection can also rely heavily on the type and quality of sensing available.
%
%SLAM with known correspondence or ``supervised SLAM,"   The algorithm does not care how the correspondence was obtained and does not perform error checking to detect false matches. Humans are very good at outlier rejection, so this class of SLAM solution often depends on hand-labeled correspondence, or at least human verification of automatic correspondence, to eliminate false matches before optimizing. Another way to guard against false correspondence is to use highly identifiable ``map features," such as cooperative transponders that report their identity, as in \cite{?} 
%
%semi-supervised examples
%
%unknown correspondence examples
%
%As discussed above, traditional underwater bathymetric mapping tasks rely on having accurate enough inertial navigation that the correspondence problem is simply not an issue. Similarly, outdoor robotic mapping missions typically use GPS to provide an initial estimate of position, which is close enough to the true position for accurate (but sometimes brittle) scan registration techniques [\cite{OriginalGraphSLAM?} \cite{stanley?} \cite{ICP}].
%
%Robots performing SLAM in indoor environments do not have access to GPS signals. Because of this, they must either have very accurate odometry (like bathymetry mapping vehicles) or be able to 

\section{SLAM-based Iceberg Profiling}

In \cite{Kimball}, a method was presented for creating high-resolution maps of free-drifting icebergs using AUVs based on SLAM principles. The method considered a single, constant-depth swath of sonar data collected by circumnavigating a free-drifting iceberg. 

Like the generic SLAM example presented above, Kimball's method used range scans to estimate accumulated drift. However, rather than estimating the drift of the \emph{vehicle} in the icebergs reference frame, the iceberg's drift in the inertial frame was estimated while the vehicle's inertial position was assumed to be known and kept fixed. This formulation of the problem, in which the environment's motion is mapped explicitly led Kimball to develop a custom solution framework. The framework allowed him to prove the feasibility of SLAM-based solutions for iceberg profiling, as shown in Figure \ref{fig:KimballSolution}, but the method was difficult to scale to the full-depth profiling process, with multiple data swaths and many loop closures. The reformulation of the problem presented in Chapter \ref{ch.IcebergGeometry} casts the problem entirely in iceberg-relative terms, allowing the problem to be solved more easily using generic SLAM methods that scale well to large problem sizes. This formulation, including similarities and differences to the generic case, will be developed more fully in Chapter \ref{ch.ProblemStatement}.

 \begin{figure}[!htb]
   \centering
   \includegraphics[width=.7\textwidth]{../graphics/PeterSolution} % requires the graphicx package
   \caption{Kimball's partial profile of an Antarctic iceberg. \emph{Graphic courtesy of Peter Kimball.}}
   \label{fig:KimballSolution}
\end{figure}

%The work uses offline optimization to estimate the iceberg's translation and rotation during the course of the mapping run. It models these motion parameters using B-splines \cite{} to enforce smooth, physical motion. The optimization problem is broken up into linear and nonlinear portions and solved in an iterative least squares framework, as shown in Figure \ref{fig:NestedLoopRelatedWork}. The method was demonstrated on field data from an Antarctic iceberg collected by ship-based sonar, as well as bathymetric data recorded by an AUV. While it provided accurate, self-consistent map sections based on constant depth swaths of data, the algorithm suffered from scalability issues. Multiple swaths of data were required to build up a map of the entire iceberg, and errors in the motion model between the swaths could cause map artifacts or ``seams" that could make later use for robotic navigation difficult. Additionally, the method was computationally intensive, and required subsampling of data for the optimization to converge in a reasonable amount of time. Furthermore, the method relied on having an estimate of the vehicle's inertial position, which was supplied to it via ship-based USBL link. The need to tend the vehicle to provide these navigation fixes places an operational burden on the ship, when a more autonomous solution could free it to do other science. This dissertation uses Kimball's method as a foundation, and makes a number of improvements to address these issues. 

\section{Summary}

A number of companies currently perform iceberg profiling using ship-based sonar, ROVs, and aerial and surface-based photogrammetry. These profiles are used to model wind and water drag to predict drift and also to aid in damage modeling and iceberg towing and management. 

Several efforts have been made to use AUVs to profile the keel of icebergs. The work presented in this dissertation builds on one of these efforts. Its contributions address issues with speed, scalability, and operational constraints of the prior method. To make these improvements, the problem is reformulated to fit within the framework of well-developed SLAM techniques. 

SLAM techniques require recognizing when an area has been traversed before. This correspondence problem can be solved by manually labeling the data, or the correspondences can be discovered by the algorithm autonomously. Generally the more information the robot is able to gather from the environment, the more this process can be automated. Much work has been done in the robotics and computer vision communities to extract robust, identifiable features from range and image data. These features can be used by the robot to identify loop closure events.

